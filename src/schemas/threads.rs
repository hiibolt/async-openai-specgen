use super::assistants_threads::AssistantToolsCode;
use super::assistants_threads::AssistantToolsFileSearch;
use super::assistants_threads::AssistantToolsFunction;

use std::collections::HashMap;
use serde::{Serialize, Deserialize};

#[derive(Debug, Serialize, Deserialize, Clone, PartialEq)]
pub struct AssistantToolsFileSearchTypeOnly {
	/// The type of tool being defined: `file_search`
	pub r#type: AssistantToolsFileSearchTypeOnlyType,
}
/// The type of tool being defined: `file_search`
#[derive(Debug, Serialize, Deserialize, Clone, PartialEq)]
#[serde(rename_all = "lowercase")]
pub enum AssistantToolsFileSearchTypeOnlyType {
	#[serde(rename = "file_search")]
	FileSearch,
}
/// Controls which (if any) tool is called by the model.
/// `none` means the model will not call any tools and instead generates a message.
/// `auto` is the default value and means the model can pick between generating a message or calling one or more tools.
/// `required` means the model must call one or more tools before responding to the user.
/// Specifying a particular tool like `{"type": "file_search"}` or `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.
#[derive(Debug, Serialize, Deserialize, Clone, PartialEq)]
#[serde(rename_all = "lowercase")]
#[serde(untagged)]
pub enum AssistantsApiToolChoiceOption {
	None(String),
	Auto(String),
	Required(String),
	AssistantsNamedToolChoice(AssistantsNamedToolChoice),
}
/// Specifies a tool the model should use. Use to force the model to call a specific tool.
#[derive(Debug, Serialize, Deserialize, Clone, PartialEq)]
pub struct AssistantsNamedToolChoice {
	#[serde(skip_serializing_if = "Option::is_none")]
	pub function: Option<AssistantsNamedToolChoiceFunction>,
	/// The type of the tool. If type is `function`, the function name must be set
	pub r#type: AssistantsNamedToolChoiceType,
}
#[derive(Debug, Serialize, Deserialize, Clone, PartialEq)]
pub struct AssistantsNamedToolChoiceFunction {
	/// The name of the function to call.
	pub name: String,
}
/// The type of the tool. If type is `function`, the function name must be set
#[derive(Debug, Serialize, Deserialize, Clone, PartialEq)]
#[serde(rename_all = "lowercase")]
pub enum AssistantsNamedToolChoiceType {
	Function,
	#[serde(rename = "code_interpreter")]
	CodeInterpreter,
	#[serde(rename = "file_search")]
	FileSearch,
}
#[derive(Debug, Serialize, Deserialize, Clone, PartialEq)]
pub struct CreateMessageRequest {
	/// A list of files attached to the message, and the tools they should be added to.
	#[serde(skip_serializing_if = "Option::is_none")]
	pub attachments: Option<Vec<CreateMessageRequestAttachmentsItem>>,
	pub content: CreateMessageRequestContent,
	#[serde(skip_serializing_if = "Option::is_none")]
	pub metadata: Option<Metadata>,
	/// The role of the entity that is creating the message. Allowed values include:
	/// - `user`: Indicates the message is sent by an actual user and should be used in most cases to represent user-generated messages.
	/// - `assistant`: Indicates the message is generated by the assistant. Use this value to insert messages from the assistant into the conversation.
	pub role: CreateMessageRequestRole,
}
#[derive(Debug, Serialize, Deserialize, Clone, PartialEq, Default)]
pub struct CreateMessageRequestAttachmentsItem {
	/// The ID of the file to attach to the message.
	#[serde(skip_serializing_if = "Option::is_none")]
	pub file_id: Option<String>,
	/// The tools to add this file to.
	#[serde(skip_serializing_if = "Option::is_none")]
	pub tools: Option<Vec<CreateMessageRequestAttachmentsItemItems>>,
}
#[derive(Debug, Serialize, Deserialize, Clone, PartialEq)]
#[serde(rename_all = "lowercase")]
#[serde(untagged)]
pub enum CreateMessageRequestAttachmentsItemItems {
	AssistantToolsCode(AssistantToolsCode),
	AssistantToolsFileSearchTypeOnly(AssistantToolsFileSearchTypeOnly),
}
#[derive(Debug, Serialize, Deserialize, Clone, PartialEq)]
#[serde(rename_all = "lowercase")]
#[serde(untagged)]
pub enum CreateMessageRequestContent {
	String(String),
	CreateMessageRequestContentVariedArray(CreateMessageRequestContentVariedArray),
}
#[derive(Debug, Serialize, Deserialize, Clone, PartialEq)]
#[serde(rename_all = "lowercase")]
#[serde(untagged)]
pub enum CreateMessageRequestContentItems {
	MessageContentImageFileObject(MessageContentImageFileObject),
	MessageContentImageUrlObject(MessageContentImageUrlObject),
	MessageRequestContentTextObject(MessageRequestContentTextObject),
}
/// The role of the entity that is creating the message. Allowed values include:
/// - `user`: Indicates the message is sent by an actual user and should be used in most cases to represent user-generated messages.
/// - `assistant`: Indicates the message is generated by the assistant. Use this value to insert messages from the assistant into the conversation.
#[derive(Debug, Serialize, Deserialize, Clone, PartialEq)]
#[serde(rename_all = "lowercase")]
pub enum CreateMessageRequestRole {
	User,
	Assistant,
}
#[derive(Debug, Serialize, Deserialize, Clone, PartialEq)]
pub struct CreateRunRequest {
	/// Appends additional instructions at the end of the instructions for the run. This is useful for modifying the behavior on a per-run basis without overriding other instructions.
	#[serde(skip_serializing_if = "Option::is_none")]
	pub additional_instructions: Option<String>,
	/// Adds additional messages to the thread before creating the run.
	#[serde(skip_serializing_if = "Option::is_none")]
	pub additional_messages: Option<Vec<CreateMessageRequest>>,
	/// The ID of the [assistant](https://platform.openai.com/docs/api-reference/assistants) to use to execute this run.
	pub assistant_id: String,
	/// Overrides the [instructions](https://platform.openai.com/docs/api-reference/assistants/createAssistant) of the assistant. This is useful for modifying the behavior on a per-run basis.
	#[serde(skip_serializing_if = "Option::is_none")]
	pub instructions: Option<String>,
	/// The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.
	#[serde(skip_serializing_if = "Option::is_none")]
	pub max_completion_tokens: Option<i64>,
	/// The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.
	#[serde(skip_serializing_if = "Option::is_none")]
	pub max_prompt_tokens: Option<i64>,
	#[serde(skip_serializing_if = "Option::is_none")]
	pub metadata: Option<Metadata>,
	/// The ID of the [Model](https://platform.openai.com/docs/api-reference/models) to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used.
	#[serde(skip_serializing_if = "Option::is_none")]
	pub model: Option<CreateRunRequestModel>,
	#[serde(skip_serializing_if = "Option::is_none")]
	pub parallel_tool_calls: Option<ParallelToolCalls>,
	#[serde(skip_serializing_if = "Option::is_none")]
	pub reasoning_effort: Option<ReasoningEffort>,
	#[serde(skip_serializing_if = "Option::is_none")]
	pub response_format: Option<AssistantsApiResponseFormatOption>,
	/// If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.
	#[serde(skip_serializing_if = "Option::is_none")]
	pub stream: Option<bool>,
	/// What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.
	#[serde(skip_serializing_if = "Option::is_none")]
	pub temperature: Option<f64>,
	#[serde(skip_serializing_if = "Option::is_none")]
	pub tool_choice: Option<CreateRunRequestToolChoice>,
	/// Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis.
	#[serde(skip_serializing_if = "Option::is_none")]
	pub tools: Option<Vec<CreateRunRequestItems>>,
	/// An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.
	/// 
	/// We generally recommend altering this or temperature but not both.
	#[serde(skip_serializing_if = "Option::is_none")]
	pub top_p: Option<f64>,
	#[serde(skip_serializing_if = "Option::is_none")]
	pub truncation_strategy: Option<CreateRunRequestTruncationStrategy>,
}
#[derive(Debug, Serialize, Deserialize, Clone, PartialEq)]
#[serde(rename_all = "lowercase")]
#[serde(untagged)]
pub enum CreateRunRequestItems {
	AssistantToolsCode(AssistantToolsCode),
	AssistantToolsFileSearch(AssistantToolsFileSearch),
	AssistantToolsFunction(AssistantToolsFunction),
}
#[derive(Debug, Serialize, Deserialize, Clone, PartialEq)]
pub struct CreateRunRequestTruncationStrategy {
	/// The number of most recent messages from the thread when constructing the context for the run.
	#[serde(skip_serializing_if = "Option::is_none")]
	pub last_messages: Option<i64>,
	/// The truncation strategy to use for the thread. The default is `auto`. If set to `last_messages`, the thread will be truncated to the n most recent messages in the thread. When set to `auto`, messages in the middle of the thread will be dropped to fit the context length of the model, `max_prompt_tokens`.
	pub r#type: TruncationObjectType,
}
#[derive(Debug, Serialize, Deserialize, Clone, PartialEq)]
pub struct CreateThreadAndRunRequest {
	/// The ID of the [assistant](https://platform.openai.com/docs/api-reference/assistants) to use to execute this run.
	pub assistant_id: String,
	/// Override the default system message of the assistant. This is useful for modifying the behavior on a per-run basis.
	#[serde(skip_serializing_if = "Option::is_none")]
	pub instructions: Option<String>,
	/// The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.
	#[serde(skip_serializing_if = "Option::is_none")]
	pub max_completion_tokens: Option<i64>,
	/// The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.
	#[serde(skip_serializing_if = "Option::is_none")]
	pub max_prompt_tokens: Option<i64>,
	#[serde(skip_serializing_if = "Option::is_none")]
	pub metadata: Option<Metadata>,
	/// The ID of the [Model](https://platform.openai.com/docs/api-reference/models) to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used.
	#[serde(skip_serializing_if = "Option::is_none")]
	pub model: Option<CreateThreadAndRunRequestModel>,
	#[serde(skip_serializing_if = "Option::is_none")]
	pub parallel_tool_calls: Option<ParallelToolCalls>,
	#[serde(skip_serializing_if = "Option::is_none")]
	pub response_format: Option<AssistantsApiResponseFormatOption>,
	/// If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.
	#[serde(skip_serializing_if = "Option::is_none")]
	pub stream: Option<bool>,
	/// What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.
	#[serde(skip_serializing_if = "Option::is_none")]
	pub temperature: Option<f64>,
	#[serde(skip_serializing_if = "Option::is_none")]
	pub thread: Option<CreateThreadRequest>,
	#[serde(skip_serializing_if = "Option::is_none")]
	pub tool_choice: Option<CreateThreadAndRunRequestToolChoice>,
	/// A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.
	#[serde(skip_serializing_if = "Option::is_none")]
	pub tool_resources: Option<CreateThreadAndRunRequestToolResources>,
	/// Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis.
	#[serde(skip_serializing_if = "Option::is_none")]
	pub tools: Option<Vec<CreateThreadAndRunRequestItems>>,
	/// An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.
	/// 
	/// We generally recommend altering this or temperature but not both.
	#[serde(skip_serializing_if = "Option::is_none")]
	pub top_p: Option<f64>,
	#[serde(skip_serializing_if = "Option::is_none")]
	pub truncation_strategy: Option<CreateThreadAndRunRequestTruncationStrategy>,
}
#[derive(Debug, Serialize, Deserialize, Clone, PartialEq)]
#[serde(rename_all = "lowercase")]
#[serde(untagged)]
pub enum CreateThreadAndRunRequestItems {
	AssistantToolsCode(AssistantToolsCode),
	AssistantToolsFileSearch(AssistantToolsFileSearch),
	AssistantToolsFunction(AssistantToolsFunction),
}
/// A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.
#[derive(Debug, Serialize, Deserialize, Clone, PartialEq, Default)]
pub struct CreateThreadAndRunRequestToolResources {
	#[serde(skip_serializing_if = "Option::is_none")]
	pub code_interpreter: Option<CreateThreadAndRunRequestToolResourcesCodeInterpreter>,
	#[serde(skip_serializing_if = "Option::is_none")]
	pub file_search: Option<CreateThreadAndRunRequestToolResourcesFileSearch>,
}
#[derive(Debug, Serialize, Deserialize, Clone, PartialEq, Default)]
pub struct CreateThreadAndRunRequestToolResourcesCodeInterpreter {
	/// A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made available to the `code_interpreter` tool. There can be a maximum of 20 files associated with the tool.
	#[serde(skip_serializing_if = "Option::is_none")]
	pub file_ids: Option<Vec<String>>,
}
#[derive(Debug, Serialize, Deserialize, Clone, PartialEq, Default)]
pub struct CreateThreadAndRunRequestToolResourcesFileSearch {
	/// The ID of the [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object) attached to this assistant. There can be a maximum of 1 vector store attached to the assistant.
	#[serde(skip_serializing_if = "Option::is_none")]
	pub vector_store_ids: Option<Vec<String>>,
}
#[derive(Debug, Serialize, Deserialize, Clone, PartialEq)]
pub struct CreateThreadAndRunRequestTruncationStrategy {
	/// The number of most recent messages from the thread when constructing the context for the run.
	#[serde(skip_serializing_if = "Option::is_none")]
	pub last_messages: Option<i64>,
	/// The truncation strategy to use for the thread. The default is `auto`. If set to `last_messages`, the thread will be truncated to the n most recent messages in the thread. When set to `auto`, messages in the middle of the thread will be dropped to fit the context length of the model, `max_prompt_tokens`.
	pub r#type: TruncationObjectType,
}
/// Options to create a new thread. If no thread is provided when running a 
/// request, an empty thread will be created.
#[derive(Debug, Serialize, Deserialize, Clone, PartialEq, Default)]
pub struct CreateThreadRequest {
	/// A list of [messages](https://platform.openai.com/docs/api-reference/messages) to start the thread with.
	#[serde(skip_serializing_if = "Option::is_none")]
	pub messages: Option<Vec<CreateMessageRequest>>,
	#[serde(skip_serializing_if = "Option::is_none")]
	pub metadata: Option<Metadata>,
	/// A set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.
	#[serde(skip_serializing_if = "Option::is_none")]
	pub tool_resources: Option<CreateThreadRequestToolResources>,
}
/// A set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.
#[derive(Debug, Serialize, Deserialize, Clone, PartialEq, Default)]
pub struct CreateThreadRequestToolResources {
	#[serde(skip_serializing_if = "Option::is_none")]
	pub code_interpreter: Option<CreateThreadRequestToolResourcesCodeInterpreter>,
	#[serde(skip_serializing_if = "Option::is_none")]
	pub file_search: Option<CreateThreadRequestToolResourcesFileSearch>,
}
#[derive(Debug, Serialize, Deserialize, Clone, PartialEq, Default)]
pub struct CreateThreadRequestToolResourcesCodeInterpreter {
	/// A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made available to the `code_interpreter` tool. There can be a maximum of 20 files associated with the tool.
	#[serde(skip_serializing_if = "Option::is_none")]
	pub file_ids: Option<Vec<String>>,
}
#[derive(Debug, Serialize, Deserialize, Clone, PartialEq)]
#[serde(rename_all = "lowercase")]
#[serde(untagged)]
pub enum CreateThreadRequestToolResourcesFileSearch {
}
/// References an image [File](https://platform.openai.com/docs/api-reference/files) in the content of a message.
#[derive(Debug, Serialize, Deserialize, Clone, PartialEq)]
pub struct MessageContentImageFileObject {
	pub image_file: MessageContentImageFileObjectImageFile,
	/// Always `image_file`.
	pub r#type: MessageContentImageFileObjectType,
}
#[derive(Debug, Serialize, Deserialize, Clone, PartialEq)]
pub struct MessageContentImageFileObjectImageFile {
	/// Specifies the detail level of the image if specified by the user. `low` uses fewer tokens, you can opt in to high resolution using `high`.
	#[serde(skip_serializing_if = "Option::is_none")]
	pub detail: Option<MessageContentImageFileObjectImageFileDetail>,
	/// The [File](https://platform.openai.com/docs/api-reference/files) ID of the image in the message content. Set `purpose="vision"` when uploading the File if you need to later display the file content.
	pub file_id: String,
}
/// Specifies the detail level of the image if specified by the user. `low` uses fewer tokens, you can opt in to high resolution using `high`.
#[derive(Debug, Serialize, Deserialize, Clone, PartialEq)]
#[serde(rename_all = "lowercase")]
pub enum MessageContentImageFileObjectImageFileDetail {
	Auto,
	Low,
	High,
}
/// Always `image_file`.
#[derive(Debug, Serialize, Deserialize, Clone, PartialEq)]
#[serde(rename_all = "lowercase")]
pub enum MessageContentImageFileObjectType {
	#[serde(rename = "image_file")]
	ImageFile,
}
/// References an image URL in the content of a message.
#[derive(Debug, Serialize, Deserialize, Clone, PartialEq)]
pub struct MessageContentImageUrlObject {
	pub image_url: MessageContentImageUrlObjectImageUrl,
	/// The type of the content part.
	pub r#type: MessageContentImageUrlObjectType,
}
#[derive(Debug, Serialize, Deserialize, Clone, PartialEq)]
pub struct MessageContentImageUrlObjectImageUrl {
	/// Specifies the detail level of the image. `low` uses fewer tokens, you can opt in to high resolution using `high`. Default value is `auto`
	#[serde(skip_serializing_if = "Option::is_none")]
	pub detail: Option<MessageContentImageUrlObjectImageUrlDetail>,
	/// The external URL of the image, must be a supported image types: jpeg, jpg, png, gif, webp.
	pub url: String,
}
/// Specifies the detail level of the image. `low` uses fewer tokens, you can opt in to high resolution using `high`. Default value is `auto`
#[derive(Debug, Serialize, Deserialize, Clone, PartialEq)]
#[serde(rename_all = "lowercase")]
pub enum MessageContentImageUrlObjectImageUrlDetail {
	Auto,
	Low,
	High,
}
/// The type of the content part.
#[derive(Debug, Serialize, Deserialize, Clone, PartialEq)]
#[serde(rename_all = "lowercase")]
pub enum MessageContentImageUrlObjectType {
	#[serde(rename = "image_url")]
	ImageUrl,
}
/// The text content that is part of a message.
#[derive(Debug, Serialize, Deserialize, Clone, PartialEq)]
pub struct MessageRequestContentTextObject {
	/// Text content to be sent to the model
	pub text: String,
	/// Always `text`.
	pub r#type: MessageRequestContentTextObjectType,
}
/// Always `text`.
#[derive(Debug, Serialize, Deserialize, Clone, PartialEq)]
#[serde(rename_all = "lowercase")]
pub enum MessageRequestContentTextObjectType {
	Text,
}
#[derive(Debug, Serialize, Deserialize, Clone, PartialEq, Default)]
pub struct ModifyMessageRequest {
	#[serde(skip_serializing_if = "Option::is_none")]
	pub metadata: Option<Metadata>,
}
#[derive(Debug, Serialize, Deserialize, Clone, PartialEq, Default)]
pub struct ModifyRunRequest {
	#[serde(skip_serializing_if = "Option::is_none")]
	pub metadata: Option<Metadata>,
}
#[derive(Debug, Serialize, Deserialize, Clone, PartialEq, Default)]
pub struct ModifyThreadRequest {
	#[serde(skip_serializing_if = "Option::is_none")]
	pub metadata: Option<Metadata>,
	/// A set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.
	#[serde(skip_serializing_if = "Option::is_none")]
	pub tool_resources: Option<ModifyThreadRequestToolResources>,
}
/// A set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.
#[derive(Debug, Serialize, Deserialize, Clone, PartialEq, Default)]
pub struct ModifyThreadRequestToolResources {
	#[serde(skip_serializing_if = "Option::is_none")]
	pub code_interpreter: Option<ModifyThreadRequestToolResourcesCodeInterpreter>,
	#[serde(skip_serializing_if = "Option::is_none")]
	pub file_search: Option<ModifyThreadRequestToolResourcesFileSearch>,
}
#[derive(Debug, Serialize, Deserialize, Clone, PartialEq, Default)]
pub struct ModifyThreadRequestToolResourcesCodeInterpreter {
	/// A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made available to the `code_interpreter` tool. There can be a maximum of 20 files associated with the tool.
	#[serde(skip_serializing_if = "Option::is_none")]
	pub file_ids: Option<Vec<String>>,
}
#[derive(Debug, Serialize, Deserialize, Clone, PartialEq, Default)]
pub struct ModifyThreadRequestToolResourcesFileSearch {
	/// The [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object) attached to this thread. There can be a maximum of 1 vector store attached to the thread.
	#[serde(skip_serializing_if = "Option::is_none")]
	pub vector_store_ids: Option<Vec<String>>,
}
#[derive(Debug, Serialize, Deserialize, Clone, PartialEq)]
pub struct SubmitToolOutputsRunRequest {
	/// If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.
	#[serde(skip_serializing_if = "Option::is_none")]
	pub stream: Option<bool>,
	/// A list of tools for which the outputs are being submitted.
	pub tool_outputs: Vec<SubmitToolOutputsRunRequestToolOutputsItem>,
}
#[derive(Debug, Serialize, Deserialize, Clone, PartialEq, Default)]
pub struct SubmitToolOutputsRunRequestToolOutputsItem {
	/// The output of the tool call to be submitted to continue the run.
	#[serde(skip_serializing_if = "Option::is_none")]
	pub output: Option<String>,
	/// The ID of the tool call in the `required_action` object within the run object the output is being submitted for.
	#[serde(skip_serializing_if = "Option::is_none")]
	pub tool_call_id: Option<String>,
}
/// Controls for how a thread will be truncated prior to the run. Use this to control the intial context window of the run.
#[derive(Debug, Serialize, Deserialize, Clone, PartialEq)]
pub struct TruncationObject {
	/// The number of most recent messages from the thread when constructing the context for the run.
	#[serde(skip_serializing_if = "Option::is_none")]
	pub last_messages: Option<i64>,
	/// The truncation strategy to use for the thread. The default is `auto`. If set to `last_messages`, the thread will be truncated to the n most recent messages in the thread. When set to `auto`, messages in the middle of the thread will be dropped to fit the context length of the model, `max_prompt_tokens`.
	pub r#type: TruncationObjectType,
}
/// The truncation strategy to use for the thread. The default is `auto`. If set to `last_messages`, the thread will be truncated to the n most recent messages in the thread. When set to `auto`, messages in the middle of the thread will be dropped to fit the context length of the model, `max_prompt_tokens`.
#[derive(Debug, Serialize, Deserialize, Clone, PartialEq)]
#[serde(rename_all = "lowercase")]
pub enum TruncationObjectType {
	Auto,
	#[serde(rename = "last_messages")]
	LastMessages,
}
